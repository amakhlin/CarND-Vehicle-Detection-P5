{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_imagefiles(basedir):\n",
    "    '''\n",
    "    Read files from `basedir` and store their path in cars which is returned\n",
    "    '''\n",
    "    subdirs = os.listdir(basedir)\n",
    "    cars = []\n",
    "    for subdir in subdirs:\n",
    "        cars.extend(glob.glob(basedir+subdir+'/*'))\n",
    "    return cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis(fig, rows, cols, imgs, titles=None):\n",
    "    '''\n",
    "    Plot images in `imgs` in `rows` and `cols` on `fig` with `titles`\n",
    "    '''\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.title(i+1)\n",
    "        img_dims = len(img.shape)\n",
    "        if img_dims < 3:\n",
    "            plt.imshow(img, cmap='hot')\n",
    "            if titles:\n",
    "                plt.title(titles[i])\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "            if titles:\n",
    "                plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get training data\n",
    "cars = get_imagefiles('vehicles/')\n",
    "notcars = get_imagefiles('non-vehicles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of cars: 8792\n",
      "Nuymber of non-cars 8968\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of cars: '+ str(len(cars)))\n",
    "print('Nuymber of non-cars '+ str(len(notcars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    '''\n",
    "    Return HOG features and visualization\n",
    "    '''\n",
    "\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=True)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binned Spatial Color Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    '''\n",
    "    Compute binned color features  \n",
    "    '''\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    ch1 = cv2.resize(img[:,:,0], size).ravel() \n",
    "    ch2 = cv2.resize(img[:,:,1], size).ravel() \n",
    "    ch3 = cv2.resize(img[:,:,2], size).ravel() \n",
    "    # Return the feature vector\n",
    "    return np.hstack((ch1, ch2, ch3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def color_hist(img, nbins=32):\n",
    "    '''\n",
    "    Compute color histogram features \n",
    "    '''\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9,\n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    '''\n",
    "    Extract features from a list of images\n",
    "    ''' \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)\n",
    "            \n",
    "        if spatial_feat is True:\n",
    "            # Apply bin_spatial() to get spatial color features\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        \n",
    "        if hist_feat is True:\n",
    "            # Apply color_hist() also with a color space option now\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "            \n",
    "        if hog_feat is True:\n",
    "            # Append the new feature vector to the features list\n",
    "            if hog_channel is 'ALL':\n",
    "                hog_features = []\n",
    "                for ch in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,ch],\n",
    "                                                        orient, pix_per_cell, cell_per_block,\n",
    "                                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell,\n",
    "                                                cell_per_block, vis=False, feature_vec=True)\n",
    "            file_features.append(hog_features)\n",
    "            \n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "\n",
    "color_space = 'YCrCb'\n",
    "orient = 9 # improvement up to 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL'\n",
    "spatial_size = (32, 32)\n",
    "hist_bins = 32\n",
    "spatial_feat = True\n",
    "hist_feat = True\n",
    "hog_feat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.08696413040161 seconds to extract features\n",
      "Feature vector length: 8460\n",
      "39.45 seconds to train SVC\n",
      "Test Set Accuracy =  0.9916\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier\n",
    "\n",
    "t=time.time()\n",
    "test_cars = cars\n",
    "test_notcars = notcars\n",
    "\n",
    "car_features = extract_features(test_cars, cspace=color_space, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                        spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "notcar_features = extract_features(test_notcars, cspace=color_space, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                        spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "print(time.time()-t, 'seconds to extract features')\n",
    "\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "rand_state = np.random.randint(0,100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.1, random_state=rand_state)\n",
    "\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "svc = LinearSVC()\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "print(round(time.time()-t, 2), 'seconds to train SVC')\n",
    "print('Test Set Accuracy = ', round(svc.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Windows and Searching at Multiple Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    '''\n",
    "    Change color space of image `img` to spec in `conv`\n",
    "    '''\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    '''\n",
    "    Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "    Return image with bounding boxes and heatmap\n",
    "    '''\n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 1  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                heat[ytop_draw+ystart:ytop_draw+win_draw+ystart, xbox_left:xbox_left+win_draw] += 1\n",
    "                \n",
    "    return draw_img, nxsteps*nysteps, heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    '''\n",
    "    Given a `heatmap` reject votes below `threshold`\n",
    "    '''\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    '''\n",
    "    Draw bounding boxes on `img` using data in `labels`\n",
    "    '''\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    '''\n",
    "    Process each image in the video stream, return image with bounding boxes\n",
    "    '''\n",
    "    \n",
    "    # define parameters for fine scale search\n",
    "    scale = 1.35\n",
    "    ystart = 400\n",
    "    ystop = 500\n",
    "    \n",
    "    # perform search at fine scale\n",
    "    _, _, heat1 = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    # define parameters for large scale search\n",
    "    scale = 2\n",
    "    ystart = 464\n",
    "    ystop = 656\n",
    "    \n",
    "    # perform search at large scale\n",
    "    _, _, heat2 = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    # combine heatmaps from both scales and add them to FIFO\n",
    "    heat_list.append(heat1+heat2)\n",
    "    \n",
    "    # remove oldest element once fife length is reached\n",
    "    if len(heat_list) > 20:\n",
    "        heat_list.pop(0)\n",
    "        \n",
    "    # sum up heatamps from all elements in fifo  \n",
    "    heat_int = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    for h in heat_list:\n",
    "        heat_int += h\n",
    "    \n",
    "    # threshold to reject heatmap areas with few votes\n",
    "    heat = apply_threshold(heat_int, 14)\n",
    "    \n",
    "    # identify contigous regions of remaining high confidence votes in integrated heatmap\n",
    "    labels = label(heat)\n",
    "    \n",
    "    # draw bounding boxes on image\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heat_list = []\n",
    "test_output = 'output_video.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "test_clip = clip.fl_image(process_image)\n",
    "test_clip.write_videofile(test_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
